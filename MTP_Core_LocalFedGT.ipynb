{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import libraries"
      ],
      "metadata": {
        "id": "fOAD7K7iVqIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rqILLOIsmOAj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import math\n",
        "import gc\n",
        "\n",
        "np.random.seed(10)\n",
        "tf.random.set_seed(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify GPU device"
      ],
      "metadata": {
        "id": "n7etMaHdVvVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "QpiWxhiqSY23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare simulated client data"
      ],
      "metadata": {
        "id": "8iXGawyfVy9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@ The method is to divide the whole data set into 'K' different clients / sets based on the labels.\n",
        "@ This is to define independent data division\n",
        "\n",
        "If K = 1, then all the labels belong to `1` set.\n",
        "If K = 5, then 100/20=5 sets are created with 20 items in each set.\n",
        "\"\"\"\n",
        "def filter_client_data(images, labels, K):\n",
        "    filtered_images = []\n",
        "    filtered_labels = []\n",
        "    selector = []\n",
        "\n",
        "    NC = 10\n",
        "    Step = int(NC/K)\n",
        "    for i in range(0, NC, Step):\n",
        "        selector.append(\n",
        "            np.isin(labels, np.array([j for j in range(i, i+Step)]))\n",
        "        )\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # MNIST data\n",
        "    for s in selector:\n",
        "        filtered_images.append(\n",
        "            images[s]\n",
        "        )\n",
        "        filtered_labels.append(\n",
        "            labels[s]\n",
        "        )\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # CIFAR data\n",
        "    for s in selector:\n",
        "        filtered_images.append(\n",
        "            images[s.reshape(images.shape[0])]\n",
        "        )\n",
        "        filtered_labels.append(\n",
        "            labels[s.reshape(images.shape[0])]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    return filtered_images, filtered_labels"
      ],
      "metadata": {
        "id": "g2AtMhJlmUMV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@ This is to define mixed data division\n",
        "\n",
        "If K = 1, then all the labels belong to `1` set.\n",
        "If K = 5, then 100/20=5 sets are created with 20 items in each set.\n",
        "\"\"\"\n",
        "def filter_homogenous_client_data(images, labels, K):\n",
        "    filtered_images = []\n",
        "    filtered_labels = []\n",
        "    selector = []\n",
        "\n",
        "    for i in range(K):\n",
        "        selector.append(\n",
        "            np.random.choice(len(labels), int(len(labels)/K), replace=False)\n",
        "        )\n",
        "\n",
        "\n",
        "    for s in selector:\n",
        "        filtered_images.append(\n",
        "            images[s]\n",
        "        )\n",
        "        filtered_labels.append(\n",
        "            labels[s]\n",
        "        )\n",
        "\n",
        "    return filtered_images, filtered_labels"
      ],
      "metadata": {
        "id": "zKE8HRGQmZox"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select test sample for core algorithm testing"
      ],
      "metadata": {
        "id": "A3fFvlKTV6_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_random_sample_test_data(images, labels, split):\n",
        "    x = []\n",
        "    y = []\n",
        "    clients = len(images)\n",
        "    for i in range(clients):\n",
        "        indices = np.random.randint( 0, images[i].shape[0], size=int(split*images[i].shape[0]) )\n",
        "        x.append(\n",
        "            np.take(images[i], indices, axis=0)\n",
        "        )\n",
        "        y.append(\n",
        "            np.take(labels[i], indices, axis=0)\n",
        "        )\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "9YcCmC8emewm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture initialization"
      ],
      "metadata": {
        "id": "p_I87jUgWNjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_init_model():\n",
        "    # (*) CIFAR\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(2048, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    \"\"\"\n",
        "    # (*) MNIST\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "O0lMApHpmhvP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning - Utilities"
      ],
      "metadata": {
        "id": "5E0yaJaAWWLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setting weight wrapper\n",
        "def set_weight_model(model, average_weights):\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    model.set_weights(average_weights)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "uOg83hc0mnDW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fitting weight wrapper\n",
        "def fit_model(model, x, y):\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    model.fit(x, y, epochs=30, batch_size=512)\n",
        "    return model"
      ],
      "metadata": {
        "id": "55N9cOaXmppO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning - utilities"
      ],
      "metadata": {
        "id": "h9I9zvUXWwQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FL scale model weights based on `weights` or priorities\n",
        "def fl_scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final"
      ],
      "metadata": {
        "id": "b-WUnEiVmv-6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FL summation of scaled weights\n",
        "def fl_sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    # get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "    return avg_grad\n"
      ],
      "metadata": {
        "id": "oLEBo-sCmy_4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FedAvg"
      ],
      "metadata": {
        "id": "mRiSWdcZW9Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fed_avg(models, scaling_factor):\n",
        "    scaled_local_weight_list = list()\n",
        "    for m in range(len(models)):\n",
        "        scaled_weights = fl_scale_model_weights(models[m].get_weights(), scaling_factor[m])\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "    fed_average_weights = fl_sum_scaled_weights(scaled_local_weight_list)\n",
        "    return fed_average_weights"
      ],
      "metadata": {
        "id": "7vchNzpjm3sZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local-FedGT"
      ],
      "metadata": {
        "id": "deyH0jzZW-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gt_fed_avg(models, x, y, theta):\n",
        "    clients = len(models)\n",
        "    # clustering_x, game_x, clustering_y, game_y = [None for i in range(clients)], [None for i in range(clients)], [None for i in range(clients)], [None for i in range(clients)]\n",
        "    # for i in range(clients):\n",
        "    #     clustering_x[i], game_x[i], clustering_y[i], game_y[i] = train_test_split(x[i], y[i], test_size=0.5, random_state=45)\n",
        "    gt_models = []\n",
        "    for i in range(clients):\n",
        "        accuracy = []\n",
        "        selected_models = []\n",
        "        self_model = None\n",
        "        for j in range(clients):\n",
        "            # select self model separately\n",
        "            if i == j:\n",
        "                self_model = models[j]\n",
        "            _, acc = models[j].evaluate(x[i], y[i], batch_size=512)\n",
        "            print(f\"outer client={i} inner client={j} acc={acc}\")\n",
        "            # acc = models[j].evaluate(clustering_x[i], clustering_y[i], batch_size=512)[1]\n",
        "            # Clustering selection based on client model's accuracy on\n",
        "            # self data\n",
        "            if acc >= theta:\n",
        "                accuracy.append(\n",
        "                    acc\n",
        "                )\n",
        "                selected_models.append(\n",
        "                    models[j]\n",
        "                )\n",
        "\n",
        "        # Game theory to select Fed Avg weights :\n",
        "        # Split the test set in two parts and then use 1 set to get the clustering\n",
        "        # second set to calculate accuracy for weights in fed avg\n",
        "        _n_ = len(selected_models)\n",
        "        _sum_ = sum(accuracy)\n",
        "        # weights are equal for all the clients\n",
        "        scaling_factor_strategy = [float(1)/float(_n_) for k in range(_n_)]\n",
        "        print(f\"SS GT {scaling_factor_strategy} _n_ {_n_}\")\n",
        "        gt_model_client = set_weight_model(get_init_model(), fed_avg(selected_models, scaling_factor_strategy))\n",
        "\n",
        "        # game between self_model and aggregated model to improve personalization\n",
        "        self_priority = 0.0\n",
        "        aggregated_priority = 1.0\n",
        "        combined_model = set_weight_model(get_init_model(), fed_avg([self_model, gt_model_client], [self_priority, aggregated_priority]))\n",
        "        _, combined_acc = combined_model.evaluate(x[i], y[i], batch_size=512)\n",
        "        print(f\"game between self_model and aggregated model init acc = {combined_acc}\")\n",
        "        epochs = 10\n",
        "        alpha = 0.1\n",
        "        min_diff_for_next_step = 0.05\n",
        "        while epochs > 0:\n",
        "            epochs -= 1\n",
        "            print(f\"game between self_model and aggregated model self_priority = {self_priority} aggregated_priority = {aggregated_priority}\")\n",
        "            model_1 = set_weight_model(get_init_model(), fed_avg([self_model, gt_model_client], [self_priority+alpha, aggregated_priority-alpha]))\n",
        "            _, acc_1 = model_1.evaluate(x[i], y[i], batch_size=512)\n",
        "            # model_2 = set_weight_model(get_init_model(), fed_avg([self_model, gt_model_client], [self_priority-alpha, aggregated_priority+alpha]))\n",
        "            # _, acc_2 = model_2.evaluate(x[i], y[i], batch_size=512)\n",
        "            print(f\"game between self_model and aggregated model acc_1 = {acc_1} at epoch = {epochs}\")\n",
        "            # print(f\"game between self_model and aggregated model acc_1 = {acc_2} at epoch = {epochs}\")\n",
        "            # print(f\"acc diff = {abs(acc_2 - acc_1)}\")\n",
        "            print(f\"acc diff = {abs(combined_acc - acc_1)}\")\n",
        "            if abs(combined_acc - acc_1) > min_diff_for_next_step:\n",
        "                print(\"Inside the priority manipulation step\")\n",
        "                if acc_1 > combined_acc:\n",
        "                    self_priority += alpha\n",
        "                    aggregated_priority -= alpha\n",
        "                # else:\n",
        "                #     self_priority -= alpha\n",
        "                #     aggregated_priority += alpha\n",
        "                print(f\"game between self_model and aggregated model self_priority = {self_priority} aggregated_priority = {aggregated_priority}\")\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        combined_model = set_weight_model(get_init_model(), fed_avg([self_model, gt_model_client], [self_priority, aggregated_priority]))\n",
        "\n",
        "        gt_models.append(\n",
        "            combined_model\n",
        "        )\n",
        "    return gt_models"
      ],
      "metadata": {
        "id": "35MUmC8Dm4L4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gt_fed_avg_old(models, x, y, theta):\n",
        "    gt_models = []\n",
        "    clients = len(models)\n",
        "    for i in range(clients):\n",
        "        accuracy = []\n",
        "        selected_models = []\n",
        "        for j in range(clients):\n",
        "            _, acc = models[j].evaluate(x[i], y[i], batch_size=512)\n",
        "            # Clustering selection based on client model's accuracy on\n",
        "            # self data\n",
        "            if acc >= theta:\n",
        "                accuracy.append(\n",
        "                    acc\n",
        "                )\n",
        "                selected_models.append(\n",
        "                    models[j]\n",
        "                )\n",
        "\n",
        "        # Game theory to select Fed Avg weights\n",
        "        _n_ = len(selected_models)\n",
        "        scaling_factor_strategy = [float(k)/float(_n_) for k in accuracy]\n",
        "        print(f\"SS GT {scaling_factor_strategy} _n_ {_n_}\")\n",
        "        gt_models.append(\n",
        "            set_weight_model(get_init_model(), fed_avg(selected_models, scaling_factor_strategy))\n",
        "        )\n",
        "    return gt_models"
      ],
      "metadata": {
        "id": "Ipzk8eRkLGdk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "npPUQoDDXDFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = {\n",
        "    \"run\": [],\n",
        "    \"client\": [],\n",
        "    \"fedavg_acc\": [],\n",
        "    \"gt_fedavg_acc\": []\n",
        "}"
      ],
      "metadata": {
        "id": "zyjm0JyIm6yj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(run, K, gt_test_data_split, theta, homogenous=False):\n",
        "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar100.load_data()\n",
        "    train_images = train_images / 255.0\n",
        "    test_images = test_images / 255.0\n",
        "    print(f\"Data downloaded for train:{train_images.shape} and test:{test_images.shape}\")\n",
        "\n",
        "    if not homogenous:\n",
        "        train_x, train_y = filter_client_data(train_images, train_labels, K)\n",
        "        print(f\"Train data filtered as localized client data\")\n",
        "\n",
        "        test_x, test_y = filter_client_data(test_images, test_labels, K)\n",
        "    else:\n",
        "        train_x, train_y = filter_homogenous_client_data(train_images, train_labels, K)\n",
        "        print(f\"Train data filtered as localized client data\")\n",
        "\n",
        "        test_x, test_y = filter_homogenous_client_data(test_images, test_labels, K)\n",
        "\n",
        "    game_x, game_y = pick_random_sample_test_data(test_x, test_y, gt_test_data_split)\n",
        "    print(f\"Sampling from test data completed for game rounds in game theory federated average\")\n",
        "\n",
        "    local_models = []\n",
        "\n",
        "    fed_avg_scaling_factor = [float(1/K) for i in range(K)]\n",
        "\n",
        "    clients = len(train_x)\n",
        "\n",
        "    for i in range(clients):\n",
        "        local_models.append(\n",
        "            fit_model(get_init_model(), train_x[i], train_y[i])\n",
        "        )\n",
        "        print(f\"Local model build completed for client={i+1}\")\n",
        "\n",
        "    fed_avg_model = set_weight_model(get_init_model(), fed_avg(local_models, fed_avg_scaling_factor))\n",
        "    print(f\"Federated average aggregation completed\")\n",
        "\n",
        "    gt_fed_avg_models = gt_fed_avg(local_models, game_x, game_y, theta)\n",
        "    print(f\"Game theory based federated average aggregation completed\")\n",
        "\n",
        "    for j in range(clients):\n",
        "        df_data[\"run\"].append(run)\n",
        "\n",
        "        df_data[\"client\"].append(j+1)\n",
        "\n",
        "        _, fedavg_acc = fed_avg_model.evaluate(test_x[j], test_y[j], batch_size=512)\n",
        "        df_data[\"fedavg_acc\"].append(fedavg_acc)\n",
        "\n",
        "        _, gt_fedavg_acc = gt_fed_avg_models[j].evaluate(test_x[j], test_y[j], batch_size=512)\n",
        "        df_data[\"gt_fedavg_acc\"].append(gt_fedavg_acc)\n",
        "\n",
        "        print(f\"Debug data {fed_avg_model.evaluate(test_x[j], test_y[j], batch_size=512)}\")\n",
        "\n",
        "        print(f\"Evaluation completed for client={j+1}\")"
      ],
      "metadata": {
        "id": "AhUPj_Iom_6Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def driver(K_param, gts_param, theta_param, homogenous_param):\n",
        "    runs = 1\n",
        "    K = int(K_param)\n",
        "    gts = float(gts_param)\n",
        "    theta = float(theta_param)\n",
        "    homogenous = int(homogenous_param)\n",
        "    homogenity = {\n",
        "        0: False,\n",
        "        1: True\n",
        "    }\n",
        "    for run_id in range(1,runs+1):\n",
        "        main(run_id, K, gts, theta, homogenous=homogenity[homogenous])\n",
        "\n",
        "    df = pd.DataFrame(df_data)\n",
        "    agg_df = df.groupby('client', as_index=False).mean()[['fedavg_acc', 'gt_fedavg_acc']]\n",
        "    agg_df  = agg_df.astype(float)\n",
        "    agg_df.to_csv(f'K={K}_homogenity={str(homogenity[homogenous])}_theta={theta}.csv', index=False)"
      ],
      "metadata": {
        "id": "VM-1bo4ynAue"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# driver(5, 0.5, 0.01, 0)\n",
        "# driver(10, 0.5, 0.01, 0)\n",
        "driver(10, 0.5, 0.01, 1)\n",
        "# K = number of clients,\n",
        "# gts_param = game theory param for test data split\n",
        "# theta_param = threshold for GT\n",
        "# homogenous_param = 0: false, 1: true"
      ],
      "metadata": {
        "id": "kV8YCDtLnWjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "0GK0c1s3nwJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['fmnist', 'cifar10', 'cifar100']\n",
        "\n",
        "base_path = 'results'\n",
        "\n",
        "for d in datasets:\n",
        "    files = glob.glob(os.path.join(base_path, d, '*.csv'))\n",
        "    print(f\"Dataset = {d}\")\n",
        "    for f in files:\n",
        "        df = pd.read_csv(f)\n",
        "        _K, _h = f.split('_')[0], f.split('_')[1]\n",
        "        _K = _K.split('=')[1]\n",
        "        _h = _h.split('=')[1]\n",
        "        if _K == '5':\n",
        "            heterogenity = 'EXTREME'\n",
        "        else:\n",
        "            if _h == \"True\":\n",
        "                heterogenity = 'HOMOGENOUS'\n",
        "            else:\n",
        "                heterogenity = 'SEVERE'\n",
        "        print(f\"Heterogenity = {heterogenity} | Average accuracy = {df['gt_fedavg_acc'].mean()}\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "Siiyk0Z0nvFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0wzTM8RS70s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}